{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor  = tf.placeholder(shape=(None, 28, 28, 1), dtype=\"float32\", name=\"input_tensor\")\n",
    "output_tensor = tf.placeholder(shape=(None, 10), dtype=\"float32\", name=\"input_tensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "layer_1 = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), strides = (1, 1), activation = \"relu\")(input_tensor)\n",
    "layer_2 = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), strides = (2, 2), activation = \"relu\")(layer_1)\n",
    "layer_3 = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), strides = (2, 2), activation = \"relu\")(layer_2)\n",
    "layer_4 = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), strides = (2, 2), activation = \"relu\")(layer_3)\n",
    "layer_5 = tf.keras.layers.AveragePooling2D(pool_size= 2, strides =1)(layer_4) \n",
    "layer_6 = tf.keras.layers.Dense(units= 10)(layer_5)\n",
    "layer_7 = tf.reshape(layer_6,shape = (-1, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_1 = tf.keras.layers.c=Conv2D(input_tensor, kernel_size=(3,3), filters=32, strides=(1, 1), activation=\"relu\")\n",
    "# layer_2 = tf.layers.conv2d(layer_1, kernel_size=(3,3), filters=32, strides=(2, 2), activation=\"relu\")\n",
    "# layer_3 = tf.layers.conv2d(layer_2, kernel_size=(3,3), filters=64, strides=(2, 2), activation=\"relu\")\n",
    "# layer_4 = tf.layers.conv2d(layer_3, kernel_size=(3,3), filters=128, strides=(2, 2), activation=\"relu\")\n",
    "# layer_5 = tf.layers.average_pooling2d(layer_4, pool_size=2,strides=1)\n",
    "# layer_6 = tf.layers.dense(layer_5, units=10)\n",
    "# layer_7 = tf.reshape(layer_6, shape=(-1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2d/Relu:0\", shape=(?, 26, 26, 32), dtype=float32)\n",
      "Tensor(\"conv2d_1/Relu:0\", shape=(?, 12, 12, 32), dtype=float32)\n",
      "Tensor(\"conv2d_2/Relu:0\", shape=(?, 5, 5, 64), dtype=float32)\n",
      "Tensor(\"conv2d_3/Relu:0\", shape=(?, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"average_pooling2d/AvgPool:0\", shape=(?, 1, 1, 128), dtype=float32)\n",
      "Tensor(\"dense/BiasAdd:0\", shape=(?, 1, 1, 10), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(layer_1)\n",
    "print(layer_2)\n",
    "print(layer_3)\n",
    "print(layer_4)\n",
    "print(layer_5)\n",
    "print(layer_6)\n",
    "print(layer_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = layer_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=output_tensor, logits=prediction) # tf.reduce_mean(tf.squared_difference(output_tensor, prediction))\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.arg_max(prediction, 1), tf.arg_max(output_tensor, 1)), \"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "loss_optimization = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Images :  42000\n"
     ]
    }
   ],
   "source": [
    "images_list = []\n",
    "for root, folder, files in os.walk(\"/home/grace/Documents/Mnist_DataSet/Train_Data/\"):\n",
    "    for file in files :\n",
    "        images_list.append(root + file)\n",
    "print(\"No of Images : \", len(images_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess= tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Accuracy : 0.16666667 Loss : 0.6911525\n",
      "Epoch : 1 Accuracy : 0.96666664 Loss : 0.07912721\n",
      "Epoch : 2 Accuracy : 0.96666664 Loss : 0.020430183\n",
      "Epoch : 3 Accuracy : 0.96666664 Loss : 0.014013313\n",
      "Epoch : 4 Accuracy : 1.0 Loss : 0.0102731595\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "batch = 30\n",
    "total_images = len(images_list)\n",
    "for epoch in range(num_epochs):\n",
    "    acc_list = []\n",
    "    loss_list = []\n",
    "    for i in range(0, total_images-batch, batch):\n",
    "        image_batch = []\n",
    "        label_batch = []\n",
    "        for image in images_list[i:i+batch]:\n",
    "            single_image = cv2.imread(image, 0)/255.0 - 0.5\n",
    "            single_image = np.reshape(single_image, (28,28,1))\n",
    "            image_batch.append(single_image)\n",
    "            label = int(image.split(\"/\")[-1].split(\"_\")[0])\n",
    "            label_batch.append(np.eye(10)[label])\n",
    "        label_batch = np.array(label_batch, dtype=np.float32)\n",
    "        \n",
    "        if epoch == 0:            \n",
    "            acc, loss_val = sess.run([accuracy, loss], feed_dict={input_tensor :image_batch, output_tensor : label_batch })\n",
    "            acc_list.append(acc)\n",
    "            loss_list.append(loss_val)\n",
    "        else : \n",
    "            opt, acc, loss_val = sess.run([loss_optimization, accuracy, loss], feed_dict={input_tensor :image_batch, output_tensor : label_batch })\n",
    "            acc_list.append(acc)\n",
    "            loss_list.append(loss_val)\n",
    "    print(\"Epoch : \" + str(epoch) + \" Accuracy : \" + str(np.average(acc)) + \" Loss : \" + str(np.average(loss_list)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
